"""
Utilidades para el manejo de datos del Dashboard ICE - ACTUALIZADO CON NORMALIZACI√ìN
"""

import pandas as pd
import streamlit as st
from config import COLUMN_MAPPING, DEFAULT_META, EXCEL_FILENAME
import openpyxl  # Para leer archivos Excel

# Importaci√≥n de Google Sheets (OBLIGATORIO)
try:
    from google_sheets_manager import GoogleSheetsManager
    GOOGLE_SHEETS_AVAILABLE = True
except ImportError:
    GOOGLE_SHEETS_AVAILABLE = False
    st.error("‚ùå **ERROR CR√çTICO:** No se puede importar GoogleSheetsManager. Instala las dependencias: `pip install gspread google-auth`")

class DataLoader:
    """Clase para cargar y procesar datos - SOLO GOOGLE SHEETS"""
    
    def __init__(self):
        self.df = None
        self.sheets_manager = None
        
        # Verificar que Google Sheets est√© disponible
        if not GOOGLE_SHEETS_AVAILABLE:
            st.error("‚ùå **Google Sheets no disponible.** Instala dependencias: `pip install gspread google-auth`")
            return
        
        # Inicializar Google Sheets manager
        try:
            self.sheets_manager = GoogleSheetsManager()
        except Exception as e:
            st.error(f"‚ùå Error al inicializar Google Sheets: {e}")
            self.sheets_manager = None
    
    def load_data(self):
        """Cargar datos √öNICAMENTE desde Google Sheets"""
        try:
            # Verificar que Google Sheets est√© disponible
            if not GOOGLE_SHEETS_AVAILABLE:
                st.error("‚ùå **Google Sheets no est√° disponible.** Instala las dependencias necesarias.")
                return self._create_empty_dataframe()
            
            if not self.sheets_manager:
                st.error("‚ùå **Google Sheets Manager no inicializado.** Verifica la configuraci√≥n.")
                return self._create_empty_dataframe()
            
            st.info("üîÑ Cargando datos desde Google Sheets...")
            
            # Cargar desde Google Sheets
            df = self.sheets_manager.load_data()
            
            if df is None:
                st.error("‚ùå **Error al conectar con Google Sheets.** Verifica tu configuraci√≥n.")
                return self._create_empty_dataframe()
            
            if df.empty:
                st.warning("üìã **Google Sheets est√° vac√≠o.** Puedes agregar datos desde la pesta√±a 'Gesti√≥n de Datos'.")
                return self._create_empty_dataframe()
            
            # Procesar datos
            self._process_dataframe(df)
            
            # Verificar y limpiar
            if self._verify_and_clean_dataframe(df):
                self.df = df
                st.success(f"‚úÖ **Datos cargados desde Google Sheets:** {len(df)} registros")
                return df
            else:
                st.error("‚ùå **Datos inv√°lidos en Google Sheets.** Verifica la estructura.")
                return self._create_empty_dataframe()
                
        except Exception as e:
            st.error(f"‚ùå **Error cr√≠tico al cargar desde Google Sheets:** {e}")
            return self._create_empty_dataframe()
    
    def _create_empty_dataframe(self):
        """Crear DataFrame vac√≠o con estructura correcta"""
        empty_df = pd.DataFrame(columns=[
            'Linea_Accion', 'Componente', 'Categoria', 
            'Codigo', 'Indicador', 'Valor', 'Fecha', 'Meta', 'Peso', 'Tipo', 'Valor_Normalizado'
        ])
        
        # Asegurar tipos correctos
        empty_df['Valor'] = empty_df['Valor'].astype(float)
        empty_df['Meta'] = empty_df['Meta'].astype(float)
        empty_df['Peso'] = empty_df['Peso'].astype(float)
        empty_df['Valor_Normalizado'] = empty_df['Valor_Normalizado'].astype(float)
        
        return empty_df
    
    def _process_dataframe(self, df):
        """Procesar DataFrame de Google Sheets"""
        try:
            if df.empty:
                return
            
            # Renombrar columnas de Google Sheets a formato interno
            for original, nuevo in COLUMN_MAPPING.items():
                if original in df.columns:
                    df.rename(columns={original: nuevo}, inplace=True)
            
            # Procesar fechas
            self._process_dates(df)
            
            # Procesar valores
            self._process_values(df)
            
            # A√±adir columnas por defecto
            self._add_default_columns(df)
            
            # NUEVO: Normalizar valores seg√∫n tipo
            self._normalize_values(df)
            
        except Exception as e:
            st.error(f"Error al procesar datos de Google Sheets: {e}")
    
    def _normalize_values(self, df):
        """Normalizar valores seg√∫n el tipo de indicador - NUEVO"""
        try:
            if df.empty or 'Valor' not in df.columns:
                return
            
            # Inicializar columna de valores normalizados
            df['Valor_Normalizado'] = df['Valor'].copy()
            
            # Si no hay columna tipo, asumir que todos son tipo "porcentaje" (0-1)
            if 'Tipo' not in df.columns:
                df['Tipo'] = 'porcentaje'
                st.info("‚ÑπÔ∏è No se encontr√≥ columna 'Tipo', asumiendo todos como porcentajes (0-1)")
            
            # Normalizar por tipo de indicador
            for tipo in df['Tipo'].unique():
                if pd.isna(tipo):
                    continue
                    
                mask = df['Tipo'] == tipo
                valores = df.loc[mask, 'Valor']
                
                if len(valores) == 0:
                    continue
                
                tipo_lower = str(tipo).lower().strip()
                
                if tipo_lower in ['porcentaje', 'percentage', '%']:
                    # Porcentajes: ya est√°n entre 0-1 o 0-100
                    if valores.max() <= 1:
                        df.loc[mask, 'Valor_Normalizado'] = valores.clip(0, 1)
                    else:
                        df.loc[mask, 'Valor_Normalizado'] = (valores / 100).clip(0, 1)
                        
                elif tipo_lower in ['numero', 'number', 'cantidad', 'count']:
                    # N√∫meros: normalizar por el m√°ximo valor del grupo
                    max_val = valores.max()
                    if max_val > 0:
                        df.loc[mask, 'Valor_Normalizado'] = (valores / max_val).clip(0, 1)
                    else:
                        df.loc[mask, 'Valor_Normalizado'] = 0
                        
                elif tipo_lower in ['moneda', 'currency', 'dinero', 'money', 'pesos', 'dolares']:
                    # Moneda: normalizar por el m√°ximo valor del grupo
                    max_val = valores.max()
                    if max_val > 0:
                        df.loc[mask, 'Valor_Normalizado'] = (valores / max_val).clip(0, 1)
                    else:
                        df.loc[mask, 'Valor_Normalizado'] = 0
                        
                elif tipo_lower in ['indice', 'index', 'ratio']:
                    # √çndices: normalizar por el m√°ximo valor del grupo
                    max_val = valores.max()
                    if max_val > 0:
                        df.loc[mask, 'Valor_Normalizado'] = (valores / max_val).clip(0, 1)
                    else:
                        df.loc[mask, 'Valor_Normalizado'] = 0
                        
                else:
                    # Tipo desconocido: normalizar por el m√°ximo valor del grupo
                    max_val = valores.max()
                    if max_val > 0:
                        df.loc[mask, 'Valor_Normalizado'] = (valores / max_val).clip(0, 1)
                    else:
                        df.loc[mask, 'Valor_Normalizado'] = 0
                    
                    st.warning(f"‚ö†Ô∏è Tipo de indicador desconocido '{tipo}', normalizando por m√°ximo del grupo")
            
            # Asegurar que todos los valores normalizados est√©n entre 0 y 1
            df['Valor_Normalizado'] = df['Valor_Normalizado'].clip(0, 1)
            
            # Reportar normalizaci√≥n
            tipos_unicos = df['Tipo'].value_counts()
            st.info(f"‚úÖ Valores normalizados por tipo: {dict(tipos_unicos)}")
            
        except Exception as e:
            st.error(f"Error al normalizar valores: {e}")
            # Fallback: usar valores originales (asumiendo que est√°n entre 0-1)
            df['Valor_Normalizado'] = df['Valor'].clip(0, 1)
    
    def _process_dates(self, df):
        """Procesar fechas de Google Sheets"""
        try:
            if df.empty or 'Fecha' not in df.columns:
                return
            
            # Google Sheets puede devolver fechas en diferentes formatos
            date_formats = [
                '%d/%m/%Y', '%d-%m-%Y', '%Y-%m-%d', 
                '%Y/%m/%d', '%m/%d/%Y', '%d.%m.%Y'
            ]
            
            fechas_convertidas = None
            
            for formato in date_formats:
                try:
                    fechas_convertidas = pd.to_datetime(df['Fecha'], format=formato, errors='coerce')
                    # Si se convirtieron m√°s del 50% de las fechas, usar este formato
                    if fechas_convertidas.notna().sum() / len(fechas_convertidas) >= 0.5:
                        break
                except:
                    continue
            
            # Si ning√∫n formato espec√≠fico funcion√≥, usar conversi√≥n autom√°tica
            if fechas_convertidas is None or fechas_convertidas.notna().sum() == 0:
                fechas_convertidas = pd.to_datetime(df['Fecha'], errors='coerce', dayfirst=True)
            
            df['Fecha'] = fechas_convertidas
            
            # Reportar fechas inv√°lidas
            fechas_invalidas = df['Fecha'].isna().sum()
            if fechas_invalidas > 0:
                st.warning(f"‚ö†Ô∏è {fechas_invalidas} fechas no se pudieron convertir en Google Sheets")
                
        except Exception as e:
            st.warning(f"Error al procesar fechas desde Google Sheets: {e}")
    
    def _process_values(self, df):
        """Procesar valores num√©ricos de Google Sheets"""
        try:
            if df.empty or 'Valor' not in df.columns:
                return
            
            # Google Sheets puede devolver valores como strings
            if df['Valor'].dtype == 'object':
                # Reemplazar comas por puntos y limpiar espacios
                df['Valor'] = (df['Valor']
                              .astype(str)
                              .str.replace(',', '.')
                              .str.replace(' ', '')
                              .str.strip())
                
                # Convertir a num√©rico
                df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce')
            
            # Reportar valores inv√°lidos
            valores_invalidos = df['Valor'].isna().sum()
            if valores_invalidos > 0:
                st.warning(f"‚ö†Ô∏è {valores_invalidos} valores no se pudieron convertir desde Google Sheets")
                
        except Exception as e:
            st.warning(f"Error al procesar valores desde Google Sheets: {e}")
    
    def _add_default_columns(self, df):
        """A√±adir columnas por defecto si no existen"""
        if 'Meta' not in df.columns:
            df['Meta'] = DEFAULT_META
        if 'Peso' not in df.columns:
            df['Peso'] = 1.0
        if 'Tipo' not in df.columns:
            df['Tipo'] = 'porcentaje'  # Valor por defecto
        
        # Asegurar tipos correctos
        df['Meta'] = pd.to_numeric(df['Meta'], errors='coerce').fillna(DEFAULT_META)
        df['Peso'] = pd.to_numeric(df['Peso'], errors='coerce').fillna(1.0)
    
    def _verify_and_clean_dataframe(self, df):
        """Verificar y limpiar DataFrame de Google Sheets"""
        try:
            if df.empty:
                return True  # DataFrame vac√≠o pero v√°lido
            
            # Verificar columnas esenciales
            required_columns = ['Codigo', 'Fecha', 'Valor', 'Componente', 'Categoria', 'Indicador']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                st.error(f"‚ùå **Faltan columnas en Google Sheets:** {missing_columns}")
                st.error("**Columnas requeridas:** LINEA DE ACCI√ìN, COMPONENTE PROPUESTO, CATEGOR√çA, COD, Nombre de indicador, Valor, Fecha")
                st.write("**Columnas encontradas:**", list(df.columns))
                return False
            
            # Limpiar registros con datos faltantes solo en columnas cr√≠ticas
            initial_count = len(df)
            df.dropna(subset=['Codigo'], inplace=True)  # Solo c√≥digo es obligatorio
            final_count = len(df)
            
            if initial_count != final_count:
                st.info(f"üßπ Limpiados {initial_count - final_count} registros sin c√≥digo desde Google Sheets")
            
            return True
            
        except Exception as e:
            st.error(f"Error en verificaci√≥n de datos de Google Sheets: {e}")
            return False
    
    def get_data_source_info(self):
        """Obtener informaci√≥n sobre la fuente de datos"""
        if self.sheets_manager:
            return {
                'source': 'Google Sheets',
                'connection_info': self.sheets_manager.get_connection_info()
            }
        else:
            return {
                'source': 'Google Sheets (No conectado)',
                'connection_info': {'connected': False}
            }

class DataProcessor:
    """Clase para procesar y calcular m√©tricas de los datos - ACTUALIZADA"""
    
    @staticmethod
    def calculate_scores(df, fecha_filtro=None):
        """Calcular puntajes usando valores normalizados."""
        try:
            if df.empty:
                st.info("üìã No hay datos disponibles para calcular puntajes")
                return pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []}), \
                       pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []}), 0

            # SIEMPRE usar el valor m√°s reciente de cada indicador
            df_filtrado = DataProcessor._get_latest_values_by_indicator(df)

            if len(df_filtrado) == 0:
                st.info("üìã No hay datos para calcular puntajes")
                return pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []}), \
                       pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []}), 0

            # Verificar columnas esenciales incluyendo valores normalizados
            required_columns = ['Valor_Normalizado', 'Peso', 'Componente', 'Categoria']
            missing_columns = [col for col in required_columns if col not in df_filtrado.columns]
            if missing_columns:
                st.error(f"Faltan columnas esenciales: {missing_columns}")
                return pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []}), \
                       pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []}), 0

            # Usar valores normalizados directamente (ya est√°n entre 0-1)
            df_filtrado['Valor_Para_Calculo'] = df_filtrado['Valor_Normalizado'].clip(0, 1)
            
            # Verificar que tenemos datos despu√©s de la normalizaci√≥n
            if df_filtrado['Valor_Para_Calculo'].isna().all():
                st.error("Todos los valores normalizados son NaN")
                return pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []}), \
                       pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []}), 0
            
            # Calcular puntajes por componente
            try:
                puntajes_componente = DataProcessor._calculate_weighted_average_by_group(
                    df_filtrado, 'Componente'
                )
            except Exception as e:
                st.error(f"Error al calcular puntajes por componente: {e}")
                puntajes_componente = pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []})
            
            # Calcular puntajes por categor√≠a
            try:
                puntajes_categoria = DataProcessor._calculate_weighted_average_by_group(
                    df_filtrado, 'Categoria'
                )
            except Exception as e:
                st.error(f"Error al calcular puntajes por categor√≠a: {e}")
                puntajes_categoria = pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []})
            
            # Calcular puntaje general
            try:
                peso_total = df_filtrado['Peso'].sum()
                if peso_total > 0:
                    puntaje_general = (df_filtrado['Valor_Para_Calculo'] * df_filtrado['Peso']).sum() / peso_total
                else:
                    puntaje_general = df_filtrado['Valor_Para_Calculo'].mean()
                
                # Verificar que el puntaje general es v√°lido
                if pd.isna(puntaje_general):
                    puntaje_general = 0.0
                    
            except Exception as e:
                st.error(f"Error al calcular puntaje general: {e}")
                puntaje_general = 0.0

            return puntajes_componente, puntajes_categoria, puntaje_general
            
        except Exception as e:
            st.error(f"Error cr√≠tico en calculate_scores: {e}")
            return pd.DataFrame({'Componente': [], 'Puntaje_Ponderado': []}), \
                   pd.DataFrame({'Categoria': [], 'Puntaje_Ponderado': []}), 0
    
    @staticmethod
    def _get_latest_values_by_indicator(df):
        """Obtener el valor m√°s reciente de cada indicador."""
        try:
            if df.empty:
                return df
            
            # Verificar que tenemos las columnas necesarias
            required_columns = ['Codigo', 'Fecha', 'Valor']
            if not all(col in df.columns for col in required_columns):
                st.error(f"Faltan columnas requeridas: {required_columns}")
                return df
            
            # Remover filas con valores NaN en columnas cr√≠ticas
            df_clean = df.dropna(subset=['Codigo', 'Fecha', 'Valor']).copy()
            
            if df_clean.empty:
                return df
            
            # Usar sort_values y groupby para obtener valores m√°s recientes
            df_latest = (df_clean
                        .sort_values(['Codigo', 'Fecha'])
                        .groupby('Codigo', as_index=False)
                        .last()
                        .reset_index(drop=True))
            
            return df_latest
            
        except Exception as e:
            st.error(f"Error al obtener valores m√°s recientes: {e}")
            return df
    
    @staticmethod
    def _calculate_weighted_average_by_group(df, group_column):
        """Calcular promedio ponderado por grupo usando valores normalizados"""
        try:
            if df.empty:
                return pd.DataFrame(columns=[group_column, 'Puntaje_Ponderado'])
            
            if group_column not in df.columns:
                st.error(f"La columna '{group_column}' no existe en los datos")
                return pd.DataFrame(columns=[group_column, 'Puntaje_Ponderado'])
            
            # Verificar que tenemos las columnas necesarias
            required_cols = ['Valor_Para_Calculo', 'Peso']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                st.error(f"Faltan columnas necesarias: {missing_cols}")
                return pd.DataFrame(columns=[group_column, 'Puntaje_Ponderado'])
            
            # Funci√≥n para calcular promedio ponderado
            def weighted_avg(valores, pesos):
                mask = pd.notna(valores) & pd.notna(pesos)
                if not mask.any():
                    return 0.0
                
                valores_clean = valores[mask]
                pesos_clean = pesos[mask]
                peso_total = pesos_clean.sum()
                
                if peso_total > 0:
                    return (valores_clean * pesos_clean).sum() / peso_total
                else:
                    return valores_clean.mean() if len(valores_clean) > 0 else 0.0
            
            # Calcular promedio ponderado por grupo
            result = df.groupby(group_column).agg({
                'Valor_Para_Calculo': list,
                'Peso': list
            }).reset_index()
            
            result['Puntaje_Ponderado'] = result.apply(
                lambda row: weighted_avg(
                    pd.Series(row['Valor_Para_Calculo']), 
                    pd.Series(row['Peso'])
                ), axis=1
            )
            
            return result[[group_column, 'Puntaje_Ponderado']]
            
        except Exception as e:
            st.error(f"Error en c√°lculo ponderado por {group_column}: {e}")
            return pd.DataFrame(columns=[group_column, 'Puntaje_Ponderado'])

class DataEditor:
    """Clase para editar datos - SOLO GOOGLE SHEETS"""
    
    @staticmethod
    def add_new_record(df, codigo, fecha, valor, csv_path=None):
        """Agregar un nuevo registro a Google Sheets"""
        try:
            return DataEditor._add_record_google_sheets(df, codigo, fecha, valor)
                
        except Exception as e:
            st.error(f"‚ùå Error al agregar registro a Google Sheets: {e}")
            return False
    
    @staticmethod
    def update_record(df, codigo, fecha, nuevo_valor, csv_path=None):
        """Actualizar un registro existente en Google Sheets"""
        try:
            return DataEditor._update_record_google_sheets(codigo, fecha, nuevo_valor)
                
        except Exception as e:
            st.error(f"‚ùå Error al actualizar registro en Google Sheets: {e}")
            return False
    
    @staticmethod
    def delete_record(df, codigo, fecha, csv_path=None):
        """Eliminar un registro existente de Google Sheets"""
        try:
            return DataEditor._delete_record_google_sheets(codigo, fecha)
                
        except Exception as e:
            st.error(f"‚ùå Error al eliminar registro de Google Sheets: {e}")
            return False
    
    @staticmethod
    def _add_record_google_sheets(df, codigo, fecha, valor):
        """Agregar registro a Google Sheets"""
        try:
            if not GOOGLE_SHEETS_AVAILABLE:
                st.error("‚ùå Google Sheets no disponible")
                return False
            
            sheets_manager = GoogleSheetsManager()
            
            # Buscar informaci√≥n base del indicador
            if df.empty:
                st.error(f"‚ùå No hay datos base disponibles para crear el registro")
                return False
            
            indicador_existente = df[df['Codigo'] == codigo]
            if indicador_existente.empty:
                st.error(f"‚ùå No se encontr√≥ informaci√≥n base para el c√≥digo {codigo}")
                st.info("üí° Aseg√∫rate de que el c√≥digo existe en Google Sheets")
                return False
            
            indicador_base = indicador_existente.iloc[0]
            
            # Formatear fecha
            if hasattr(fecha, 'strftime'):
                fecha_formateada = fecha.strftime('%d/%m/%Y')
            else:
                fecha_formateada = pd.to_datetime(fecha).strftime('%d/%m/%Y')
            
            # Crear diccionario de datos para Google Sheets
            data_dict = {
                'LINEA DE ACCI√ìN': indicador_base.get('Linea_Accion', ''),
                'COMPONENTE PROPUESTO': indicador_base.get('Componente', ''),
                'CATEGOR√çA': indicador_base.get('Categoria', ''),
                'COD': codigo,
                'Nombre de indicador': indicador_base.get('Indicador', ''),
                'Valor': valor,
                'Fecha': fecha_formateada,
                'Tipo': indicador_base.get('Tipo', 'porcentaje')  # Incluir tipo
            }
            
            # Agregar a Google Sheets
            success = sheets_manager.add_record(data_dict)
            
            if success:
                # Forzar recarga de cache
                st.cache_data.clear()
                st.session_state.data_timestamp = st.session_state.get('data_timestamp', 0) + 1
            
            return success
            
        except Exception as e:
            st.error(f"‚ùå Error en Google Sheets: {e}")
            return False
    
    @staticmethod
    def _update_record_google_sheets(codigo, fecha, nuevo_valor):
        """Actualizar registro en Google Sheets"""
        try:
            if not GOOGLE_SHEETS_AVAILABLE:
                st.error("‚ùå Google Sheets no disponible")
                return False
            
            sheets_manager = GoogleSheetsManager()
            success = sheets_manager.update_record(codigo, fecha, nuevo_valor)
            
            if success:
                # Forzar recarga de cache
                st.cache_data.clear()
                st.session_state.data_timestamp = st.session_state.get('data_timestamp', 0) + 1
            
            return success
            
        except Exception as e:
            st.error(f"‚ùå Error en Google Sheets: {e}")
            return False
    
    @staticmethod
    def _delete_record_google_sheets(codigo, fecha):
        """Eliminar registro de Google Sheets"""
        try:
            if not GOOGLE_SHEETS_AVAILABLE:
                st.error("‚ùå Google Sheets no disponible")
                return False
            
            sheets_manager = GoogleSheetsManager()
            success = sheets_manager.delete_record(codigo, fecha)
            
            if success:
                # Forzar recarga de cache
                st.cache_data.clear()
                st.session_state.data_timestamp = st.session_state.get('data_timestamp', 0) + 1
            
            return success
            
        except Exception as e:
            st.error(f"‚ùå Error en Google Sheets: {e}")
            return False

    # Funci√≥n de compatibilidad
    @staticmethod
    def save_edit(df, codigo, fecha, nuevo_valor, csv_path):
        """Funci√≥n de compatibilidad"""
        return DataEditor.update_record(df, codigo, fecha, nuevo_valor, None)

class ExcelDataLoader:
    """Clase para cargar datos del archivo Excel con hojas metodol√≥gicas"""
    
    def __init__(self):
        import os
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.excel_path = os.path.join(self.script_dir, EXCEL_FILENAME)
        self.metodologicas_data = None
    
    def load_excel_data(self):
        """Cargar datos del Excel"""
        try:
            import os
            if not os.path.exists(self.excel_path):
                return None
            
            df_metodologicas = pd.read_excel(
                self.excel_path, 
                sheet_name="Hoja metodol√≥gica indicadores",
                header=1
            )
            
            column_mapping = {
                'C1_ID': 'Codigo',
                'C2_Nombre indicador': 'Nombre_Indicador',
                'C3_Definici√≥n': 'Definicion',
                'C4_Objetivo': 'Objetivo',
                'C5_√Årea tem√°tica': 'Area_Tematica',
                'C6_Tema': 'Tema',
                'C7_Soporte Legal': 'Soporte_Legal',
                'C8_F√≥rmula de c√°lculo': 'Formula_Calculo',
                'C9_Variables': 'Variables',
                'C10_Unidad de medida': 'Unidad_Medida',
                'C11_Fuente de Informaci√≥n': 'Fuente_Informacion',
                'C12_Tipo de indicador': 'Tipo_Indicador',
                'C13_Periodicidad ': 'Periodicidad',
                'C14_Desagregaci√≥n Geogr√°fica': 'Desagregacion_Geografica',
                'Metodolog√≠a de c√°lculo': 'Metodologia_Calculo',
                'C15_Desagregaci√≥n poblacional-diferencial': 'Desagregacion_Poblacional',
                'C16_Observaciones / Notas T√©cnicas': 'Observaciones',
                'Clasificaci√≥n seg√∫n calidad': 'Clasificacion_Calidad',
                'Clasificaci√≥n seg√∫n nivel de intervenci√≥n': 'Clasificacion_Intervencion',
                'Tipo de acumulaci√≥n': 'Tipo_Acumulacion',
                'C17_Enlaces web relacionados': 'Enlaces_Web',
                'Interpretaci√≥n': 'Interpretacion',
                'Limitaciones': 'Limitaciones',
                'C18_Sector': 'Sector',
                'C19_Entidad': 'Entidad',
                'C20_Dependencia': 'Dependencia',
                'C21_Directivo/a Responsable': 'Directivo_Responsable',
                'C22_Correo electr√≥nico del directivo': 'Correo_Directivo',
                'C23_Tel√©fono de contacto': 'Telefono_Contacto'
            }
            
            # Renombrar columnas existentes
            for old_name, new_name in column_mapping.items():
                if old_name in df_metodologicas.columns:
                    df_metodologicas = df_metodologicas.rename(columns={old_name: new_name})
            
            # Limpiar datos vac√≠os
            df_metodologicas = df_metodologicas.dropna(subset=['Codigo'])
            
            self.metodologicas_data = df_metodologicas
            st.success(f"‚úÖ Datos del Excel cargados: {len(df_metodologicas)} indicadores metodol√≥gicos")
            return df_metodologicas
            
        except Exception as e:
            st.error(f"Error al cargar datos del Excel: {e}")
            return None
    
    def get_indicator_data(self, codigo):
        """Obtener datos de un indicador espec√≠fico por c√≥digo"""
        if self.metodologicas_data is None:
            self.load_excel_data()
        
        if self.metodologicas_data is None:
            return None
        
        try:
            # Buscar el indicador por c√≥digo
            indicator_data = self.metodologicas_data[
                self.metodologicas_data['Codigo'] == codigo
            ]
            
            if len(indicator_data) > 0:
                return indicator_data.iloc[0].to_dict()
            else:
                return None
                
        except Exception as e:
            st.error(f"Error al obtener datos del indicador {codigo}: {e}")
            return None
